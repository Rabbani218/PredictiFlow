{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce8fd76",
   "metadata": {},
   "source": [
    "# 02 - Model Prototyping\n",
    "\n",
    "In this notebook we prototype the core model functions for PredictiFlow: lightweight wrappers for Prophet and ARIMA (with safe fallbacks), evaluation utilities, and a small `select_best_model` routine.\n",
    "\n",
    "Notes:\n",
    "- The code uses optional imports (Prophet, statsmodels). If these are not installed the notebook will fall back to simple baselines so you can iterate quickly.\n",
    "- Later, tested functions can be moved into `backend/app/core/forecasting.py` for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and safe optional libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional heavy libs\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except Exception:\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    STATSMODELS_AVAILABLE = True\n",
    "except Exception:\n",
    "    STATSMODELS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    SKL_AVAILABLE = True\n",
    "except Exception:\n",
    "    SKL_AVAILABLE = False\n",
    "\n",
    "print('Prophet available:', PROPHET_AVAILABLE)\n",
    "print('Statsmodels available:', STATSMODELS_AVAILABLE)\n",
    "print('sklearn available:', SKL_AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a130db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(path_or_df):\n",
    "    \"\"\"Load a CSV or accept a DataFrame and return standardized df with columns ['ds','y']\n",
    "    - ds: datetime\n",
    "    - y: float\n",
    "    \"\"\"\n",
    "    if isinstance(path_or_df, str):\n",
    "        df = pd.read_csv(path_or_df)\n",
    "    else:\n",
    "        df = path_or_df.copy()\n",
    "    df = df.iloc[:, :2].copy()\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    df = df.sort_values('ds').reset_index(drop=True)\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df['y'] = df['y'].interpolate().fillna(method='bfill').fillna(method='ffill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet wrapper with fallback baseline\n",
    "def train_prophet(df, periods=30):\n",
    "    df2 = df[['ds','y']].rename(columns={'y':'y'})\n",
    "    if PROPHET_AVAILABLE:\n",
    "        m = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
    "        m.fit(df2)\n",
    "        future = m.make_future_dataframe(periods=periods)\n",
    "        fcst = m.predict(future)[['ds','yhat']]\n",
    "        return 'prophet', fcst\n",
    "    # fallback: repeat last value\n",
    "    last = df2['y'].iloc[-1] if len(df2)>0 else 0.0\n",
    "    last_date = pd.to_datetime(df2['ds'].iloc[-1]) if len(df2)>0 else pd.Timestamp.today()\n",
    "    freq = (pd.to_datetime(df2['ds'].iloc[1]) - pd.to_datetime(df2['ds'].iloc[0])) if len(df2)>1 else pd.Timedelta(days=1)\n",
    "    future_dates = [last_date + (i+1)*freq for i in range(periods)]\n",
    "    return 'baseline_prophet', pd.DataFrame({'ds':future_dates, 'yhat':[float(last)]*periods})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA wrapper with fallback linear extrapolation\n",
    "def train_arima(df, periods=30):\n",
    "    df2 = df[['ds','y']].rename(columns={'y':'y'})\n",
    "    if STATSMODELS_AVAILABLE:\n",
    "        model = SARIMAX(df2['y'], order=(1,1,1), seasonal_order=(0,0,0,0))\n",
    "        res = model.fit(disp=False)\n",
    "        pred = res.get_forecast(steps=periods)\n",
    "        idx = pd.date_range(start=pd.to_datetime(df2['ds'].iloc[-1]) + pd.Timedelta(days=1), periods=periods)\n",
    "        return 'arima', pd.DataFrame({'ds':idx, 'yhat':pred.predicted_mean.values})\n",
    "    # fallback: linear extrapolation using last two points\n",
    "    if len(df2) >= 2:\n",
    "        x = np.arange(len(df2))\n",
    "        coef = np.polyfit(x[-2:], df2['y'].values[-2:], 1)\n",
    "        future_x = np.arange(len(df2), len(df2)+periods)\n",
    "        preds = np.polyval(coef, future_x)\n",
    "    else:\n",
    "        preds = np.array([float(df2['y'].iloc[-1] if len(df2)>0 else 0.0)]*periods)\n",
    "    last_date = pd.to_datetime(df2['ds'].iloc[-1]) if len(df2)>0 else pd.Timestamp.today()\n",
    "    freq = (pd.to_datetime(df2['ds'].iloc[1]) - pd.to_datetime(df2['ds'].iloc[0])) if len(df2)>1 else pd.Timedelta(days=1)\n",
    "    future_dates = [last_date + (i+1)*freq for i in range(periods)]\n",
    "    return 'baseline_arima', pd.DataFrame({'ds':future_dates, 'yhat':preds.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation utilities\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mae = float(np.mean(np.abs(y_true - y_pred)))\n",
    "    rmse = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        denom = np.where(np.abs(y_true) < 1e-8, 1e-8, y_true)\n",
    "        mape = float(np.mean(np.abs((y_true - y_pred)/denom))*100)\n",
    "    return {'mae':mae, 'rmse':rmse, 'mape':mape}\n",
    "\n",
    "def select_best_model(candidates):\n",
    "    \"\"\"candidates: list of tuples (name, forecast_df, metrics)\n",
    "    selects the one with lowest rmse\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    for name, fcst, metrics in candidates:\n",
    "        if best is None or metrics['rmse'] < best[2]['rmse']:\n",
    "            best = (name, fcst, metrics)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b51688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick run on sample data (data/sample_sales.csv)\n",
    "csv_path = '../data/sample_sales.csv'\n",
    "df = prepare_df(csv_path)\n",
    "prophet_name, prophet_fcst = train_prophet(df, periods=30)\n",
    "arima_name, arima_fcst = train_arima(df, periods=30)\n",
    "\n",
    "# Evaluate on the last min(30, len(df)) points\n",
    "h = min(30, len(df))\n",
    "y_true = df['y'].values[-h:]\n",
    "prophet_pred = prophet_fcst['yhat'].values[-h:] if len(prophet_fcst)>=h else prophet_fcst['yhat'].values[:h]\n",
    "arima_pred = arima_fcst['yhat'].values[:h]\n",
    "prophet_metrics = eval_metrics(y_true, prophet_pred)\n",
    "arima_metrics = eval_metrics(y_true, arima_pred)\n",
    "\n",
    "best = select_best_model([ (prophet_name, prophet_fcst, prophet_metrics), (arima_name, arima_fcst, arima_metrics) ])\n",
    "print('Best model:', best[0])\n",
    "print('Prophet metrics:', prophet_metrics)\n",
    "print('ARIMA metrics:', arima_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a1ee4",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Move tested functions (prepare_df, train_prophet, train_arima, eval_metrics, select_best_model) into `backend/app/core/forecasting.py`.\n",
    "- Add hyperparameter grid search and time-series cross-validation in a separate notebook when ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional: small hyperparameter tuning example (span tuning for exp smoothing)\n",
    "# This cell provides lightweight implementations for train_exp_smoothing,\n",
    "# rolling_origin_cv and cv_score so the example can run inside the notebook\n",
    "\n",
    "# Re-prepare df (in case notebook restarted)\n",
    "df = prepare_df('../data/sample_sales.csv')\n",
    "initial_window = max(14, int(len(df) * 0.5))\n",
    "horizon = 7\n",
    "\n",
    "# Minimal train_exp_smoothing implementation (local to notebook)\n",
    "def train_exp_smoothing(d, periods=30, span=10):\n",
    "    y = d['y'].values\n",
    "    if len(y) < 2:\n",
    "        preds = [float(y[-1]) if len(y) > 0 else 0.0] * periods\n",
    "    else:\n",
    "        ew = pd.Series(y).ewm(span=span).mean()\n",
    "        last = float(y[-1])\n",
    "        prev = float(ew.iloc[-2]) if len(ew) > 1 else float(ew.iloc[-1])\n",
    "        slope = last - prev\n",
    "        preds = [last + (i + 1) * slope for i in range(periods)]\n",
    "    last_date = pd.to_datetime(d['ds'].iloc[-1]) if len(d) > 0 else pd.Timestamp.today()\n",
    "    freq = (pd.to_datetime(d['ds'].iloc[1]) - pd.to_datetime(d['ds'].iloc[0])) if len(d) > 1 else pd.Timedelta(days=1)\n",
    "    future = [last_date + (i + 1) * freq for i in range(periods)]\n",
    "    return 'exp_smoothing', pd.DataFrame({'ds': future, 'yhat': preds})\n",
    "\n",
    "# Minimal rolling-origin CV: returns list of RMSEs for each fold\n",
    "def rolling_origin_cv(df, model_fn, initial_window, horizon, step):\n",
    "    n = len(df)\n",
    "    start = initial_window\n",
    "    results = []\n",
    "    while start + horizon <= n:\n",
    "        train = df.iloc[:start].copy()\n",
    "        test = df.iloc[start:start + horizon].copy()\n",
    "        name, fcst = model_fn(train, periods=horizon)\n",
    "        preds = fcst['yhat'].values[:len(test)] if len(fcst) >= len(test) else fcst['yhat'].values[-len(test):]\n",
    "        rmse = ( (test['y'].values - preds) ** 2 ).mean() ** 0.5\n",
    "        results.append(rmse)\n",
    "        start += step\n",
    "    return results\n",
    "\n",
    "def cv_score(rmses):\n",
    "    import numpy as _np\n",
    "    return float(_np.mean(rmses)) if len(rmses) > 0 else float('inf')\n",
    "\n",
    "# Example small grid for testing speed\n",
    "params = {'spans': [5, 7, 10, 14]}\n",
    "\n",
    "best = (None, float('inf'))\n",
    "for span in params['spans']:\n",
    "    def model_fn(d, periods, span_local=span):\n",
    "        return train_exp_smoothing(d, periods=periods, span=span_local)\n",
    "\n",
    "    res = rolling_origin_cv(df, model_fn, initial_window=initial_window, horizon=horizon, step=horizon)\n",
    "    score = cv_score(res)\n",
    "    print(f'span={span} -> cv_rmse={score:.4f}')\n",
    "    if score < best[1]:\n",
    "        best = (span, score)\n",
    "\n",
    "print('Best (example) span:', best)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
